{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import sklearn\n",
    "from dmgpred.train import get_pipeline\n",
    "from dmgpred.utils.loading import load_data\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    f1_score,\n",
    "    matthews_corrcoef,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# print the JS visualization code to the notebook\n",
    "shap.initjs()\n",
    "\n",
    "# sns.set_theme('talk')\n",
    "sklearn.set_config(transform_output=\"pandas\")\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(data_dir=\"../data/\", processed=True)\n",
    "\n",
    "X = data[\"X_train\"]\n",
    "y = data[\"y_train\"] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to xgboost\n",
    "pipe = get_pipeline(X_train, clf=XGBClassifier(n_estimators=500))\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "f1_score(y_test, y_pred, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matthews_corrcoef(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = pipe.named_steps[\"preprocessor\"]\n",
    "clf = pipe.named_steps[\"clf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = preprocessor.transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "feature_names = X_test_preprocessed.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "\n",
    "bst = clf.get_booster()\n",
    "importance_type = \"weight\"  # or \"cover\", \"gain\"\n",
    "plot_importance(bst, importance_type=\"gain\", show_values=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.Series(clf.feature_importances_, index=feature_names).sort_values(\n",
    "    ascending=True\n",
    ")\n",
    "\n",
    "feature_imp.plot(kind=\"barh\", figsize=(10, 10))\n",
    "plt.suptitle(\"Feature Importances (Gain)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../output/feature_importance.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    pipe, X_test, y_test, cmap=\"Blues\", display_labels=[\"Grade 1\", \"Grade 2\", \"Grade 3\"]\n",
    ")\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../output/confusion_matrix.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall we can see that class 1 (i.e. damage grade 2) is the most difficult class to predict. It gets mistaken a lot by damage grade 3 and sometimes 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(clf)\n",
    "explanation = explainer(X_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(X_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "shap.summary_plot(\n",
    "    [shap_values[:, :, class_ind] for class_ind in range(shap_values.shape[-1])],\n",
    "    X_test_preprocessed,\n",
    "    plot_type=\"bar\",\n",
    "    show=False,\n",
    ")\n",
    "plt.suptitle(\"SHAP Summary Plot\")\n",
    "# plt.tight_layout()\n",
    "plt.savefig(\"../output/shap_summary_plot.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(explanation[0, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = 0\n",
    "shap.plots.force(\n",
    "    explainer.expected_value[cls],\n",
    "    shap_values[0, :, cls],\n",
    "    features=X_test_preprocessed.iloc[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.force(\n",
    "    explainer.expected_value[cls],\n",
    "    shap_values[::100, :, cls],\n",
    "    feature_names=feature_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[:, :, cls], X_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.violin(\n",
    "    shap_values[:, :, cls],\n",
    "    X_test_preprocessed,\n",
    "    feature_names=feature_names,\n",
    "    plot_type=\"layered_violin\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrong Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "tmp = X_test_preprocessed.copy()\n",
    "tmp[\"target\"] = y_test\n",
    "tmp[\"pred\"] = y_pred\n",
    "misclassified = tmp.query(\"target != pred\").copy()\n",
    "X_mis = misclassified.drop(columns=[\"target\", \"pred\"])\n",
    "misclassified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_mis = shap.TreeExplainer(clf)\n",
    "shap_values_mis = explainer_mis.shap_values(X_mis)\n",
    "explanation_mis = explainer_mis(X_mis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 325\n",
    "pred_cls = misclassified.iloc[idx][\"pred\"]\n",
    "true_cls = misclassified.iloc[idx][\"target\"]\n",
    "print(f\"Predicted class: {pred_cls + 1} (actual: {true_cls + 1})\")\n",
    "shap.plots.force(\n",
    "    explainer.expected_value[pred_cls],\n",
    "    shap_values_mis[idx, :, pred_cls],\n",
    "    X_mis.iloc[idx],\n",
    "    # matplotlib=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(\n",
    "    explanation_mis[idx, :, true_cls],\n",
    "    max_display=10,\n",
    "    show=False,\n",
    ")\n",
    "plt.suptitle(\n",
    "    f\"Explanation of misclassified sample (pred: {pred_cls +1}, true: {true_cls + 1})\"\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../output/shap_waterfall.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.decision_plot(\n",
    "    explainer.expected_value[pred_cls],\n",
    "    shap_values_mis[idx, :, pred_cls],\n",
    "    X_mis.iloc[idx],\n",
    "    show=False,\n",
    ")\n",
    "plt.suptitle(\n",
    "    f\"Explanation of misclassified sample (pred: {pred_cls + 1}, true: {true_cls + 1})\"\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../output/shap_decision_plot.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision plot for all class `cls` wrong predictions\n",
    "\n",
    "\n",
    "cls = 2\n",
    "every_nth = 50\n",
    "X_mis_cls = misclassified.query(\"target == @cls\")\n",
    "X_mis_cls = X_mis_cls.drop(columns=[\"target\", \"pred\"])\n",
    "print(len(X_mis_cls))\n",
    "ind = X_mis_cls.reset_index().index[::every_nth]\n",
    "\n",
    "shap.decision_plot(\n",
    "    explainer.expected_value[cls],\n",
    "    shap_values_mis[ind, :, cls],\n",
    "    X_mis_cls[::every_nth],\n",
    "    show=False,\n",
    ")\n",
    "plt.suptitle(f\"Decision plot for subset of grade {cls + 1} misclassified samples\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"../output/shap_decision_plot_grade{cls+1}.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_preprocessed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = \"age\"\n",
    "cls = 0\n",
    "filter_ = (X_mis[\"age\"] < 100).to_numpy()\n",
    "shap.plots.scatter(\n",
    "    explanation_mis[filter_, feature, cls], alpha=0.5, hist=True, show=False\n",
    ")\n",
    "plt.suptitle(f\"SHAP values for feature '{feature}' for class {cls + 1}\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"../output/shap_scatter_{feature}.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"geo_level_1_id\", \"geo_level_2_id\", \"geo_level_3_id\"]\n",
    "cls = 2\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for feature, ax in zip(features, axs):\n",
    "    shap.plots.scatter(\n",
    "        explanation[::5, feature, cls],\n",
    "        ax=ax,\n",
    "        show=False,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "plt.suptitle(f\"SHAP values for damage grade {cls + 1}\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../output/shap_scatter.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
