{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from category_encoders.binary import BinaryEncoder\n",
    "from category_encoders.hashing import HashingEncoder\n",
    "from category_encoders.james_stein import JamesSteinEncoder\n",
    "from category_encoders.leave_one_out import LeaveOneOutEncoder\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    PowerTransformer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"../data/train_values.csv\")\n",
    "y = pd.read_csv(\"../data/train_labels.csv\")\n",
    "y = y.set_index(\"building_id\")\n",
    "X = X.set_index(\"building_id\")\n",
    "\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dmgpred.cleaning import clean\n",
    "\n",
    "X = clean(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the categoricals there are different groups. There are the 3 geo_ids that have been converted to categoricals. There is count_families which has also been conveerted to categorical with the three groups 0,1,2+ (ordinal). And there are the categories legal_ownership_status, land_surface_condition foundation_type, roof_type, ground_floor_type, other_floor_type, position, plan_configuration that were categorical from the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = cat_cols = X.select_dtypes(include=\"category\").columns\n",
    "id_cols = [col for col in X.columns if col.endswith(\"id\")]\n",
    "cat_cols = [col for col in cat_cols if col not in id_cols]\n",
    "cat_cols.remove(\"count_families\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with, I will only look at the initial categorical columns and not at geo_ids and count_families. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[id_cols] = X[id_cols].astype(\"int\")\n",
    "X_fam_encoded = OrdinalEncoder().fit_transform([X[\"count_families\"]])\n",
    "X[\"count_families\"] = X_fam_encoded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category Encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "currently: one-hot encoder for categories except ordinal encoder for count_families\n",
    "https://medium.com/@ranjanrgia/simplifying-encoder-choosing-for-categorical-variables-868bef970f13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __plot_cat_encoder_importances(encoder, X, y, cols):\n",
    "    X_cat_encoded = encoder.fit_transform(X[cols])\n",
    "    if isinstance(X_cat_encoded, pd.DataFrame):\n",
    "        X_cat_encoded_df = X_cat_encoded\n",
    "    else:\n",
    "        X_cat_encoded_df = pd.DataFrame(\n",
    "            X_cat_encoded.toarray(), columns=encoder.get_feature_names_out(cols)\n",
    "        )\n",
    "    X_copy = X.copy\n",
    "    X = X.drop(cols, axis=1)\n",
    "    X[X_cat_encoded_df.columns] = X_cat_encoded_df\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=y, random_state=0\n",
    "    )\n",
    "    normalize_cols = [\"area_percentage\", \"height_percentage\"]\n",
    "    normalizer = PowerTransformer(\"yeo-johnson\").fit(X_train[normalize_cols])\n",
    "    X_train[normalize_cols] = normalizer.transform(X_train[normalize_cols])\n",
    "    X_test[normalize_cols] = normalizer.transform(X_test[normalize_cols])\n",
    "    rf = RandomForestClassifier(n_estimators=50, max_depth=3)\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(rf.score(X_test, y_test))\n",
    "    feature_names = rf.feature_names_in_\n",
    "    importances = rf.feature_importances_\n",
    "    importances = pd.Series(importances, index=feature_names).sort_values(\n",
    "        ascending=True\n",
    "    )\n",
    "    importances.plot.barh(figsize=(10, 10))\n",
    "    plt.title(\"Overview of all feature importances\")\n",
    "    plt.show()\n",
    "    importances[encoder.get_feature_names_out(cols)].plot.barh(figsize=(10, 5))\n",
    "    plt.title(\"Overview of categorical feature importances\")\n",
    "    plt.show()\n",
    "    X = X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_encoder = OneHotEncoder()\n",
    "__plot_cat_encoder_importances(oh_encoder, X, y, cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that with the current encoding the categeorical values have an extremely low importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similar to onehot, but stores categories as binary bitstrings  \n",
    "For tree based algorithms it is better than one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_encoder = BinaryEncoder()\n",
    "__plot_cat_encoder_importances(binary_encoder, X, y, cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Hashing Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses a hash function to represent categories  \n",
    "Good for handling large datasets with high cardinality features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashing_encoder = HashingEncoder()\n",
    "__plot_cat_encoder_importances(hashing_encoder, X, y, cat_cols)\n",
    "hashing_encoder.get_feature_names_in()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the column roof type gains importance (up to 0.2) as well as lang surface condition and legal ownership status (both slightly under 0.075)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Encoder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the target encoder the function needs to be changed, because the target encoder also need the y to be fitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __plot_target_encoder_importances(encoder, X, y, cols):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=y, random_state=0\n",
    "    )\n",
    "    normalize_cols = [\"area_percentage\", \"height_percentage\"]\n",
    "    normalizer = PowerTransformer(\"yeo-johnson\").fit(X_train[normalize_cols])\n",
    "    X_train[normalize_cols] = normalizer.transform(X_train[normalize_cols])\n",
    "    X_test[normalize_cols] = normalizer.transform(X_test[normalize_cols])\n",
    "\n",
    "    encoder.fit(X_train[cols], y_train)\n",
    "    X_train[cols] = encoder.transform(X_train[cols])\n",
    "    X_test[cols] = encoder.transform(X_test[cols])\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=50, max_depth=3)\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(rf.score(X_test, y_test))\n",
    "    feature_names = rf.feature_names_in_\n",
    "    importances = rf.feature_importances_\n",
    "    importances = pd.Series(importances, index=feature_names).sort_values(\n",
    "        ascending=True\n",
    "    )\n",
    "    importances.plot.barh(figsize=(10, 10))\n",
    "    plt.title(\"Overview of all feature importances\")\n",
    "    plt.show()\n",
    "    importances[encoder.get_feature_names_out(cols)].plot.barh(figsize=(10, 5))\n",
    "    plt.title(\"Overview of categorical feature importances\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = TargetEncoder()\n",
    "__plot_target_encoder_importances(te, X, y, cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the feature importance for some features increased notably."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave One Out Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "very similar to target encoding but excludes the current rowâ€™s target when calculating the mean target for a level to reduce the effect of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loo = LeaveOneOutEncoder()\n",
    "__plot_target_encoder_importances(loo, X, y, cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### James Stein Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful in reducing overfitting in small datasets or categorical variables with many levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding is aimed to improve the estimation of the categoryâ€™s mean target by shrinking them towards a more central average. The only hyperparameter in the formula is B â€” the power of shrinking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "js = JamesSteinEncoder()\n",
    "__plot_target_encoder_importances(js, X, y, cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foundation type increases in feature importance (to about 0.28)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include Geo IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to include the Geo Ids for the case that we do not want to keep them as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[id_cols] = X[id_cols].astype(\"category\")\n",
    "cols = cat_cols + id_cols\n",
    "js = JamesSteinEncoder()\n",
    "__plot_target_encoder_importances(js, X, y, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The geo IDs increased in importance. However here it might be that the classifier overfits, especially to the geo_level_3_id, for which there are only very few buildings per ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he = HashingEncoder(n_components=11)\n",
    "__plot_cat_encoder_importances(he, X, y, cols)\n",
    "he.get_feature_names_in()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geo_level_2_id becomes the most important categorical feature (about 0.14) and other_floor_type the second most important categorical feature (about 0.13)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
